{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FNO Training with Energy Regularization\n",
    "\n",
    "Train a Fourier Neural Operator (FNO) on Darcy Flow with energy-based regularization.\n",
    "\n",
    "**Loss Function**: `0.8 × MSE + 0.2 × Energy`\n",
    "\n",
    "The energy regularization uses your trained EQM model to keep predictions physically plausible and in-distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repositories\n",
    "!git clone https://github.com/MehdiMHeydari/EQM-Training.git\n",
    "!git clone https://github.com/thuml/Neural-Solver-Library.git\n",
    "\n",
    "# Move Neural-Solver-Library to expected location\n",
    "!mv Neural-Solver-Library /content/EQM-Training/Neural-Solver-Library-main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch torchvision einops omegaconf h5py matplotlib scipy tqdm timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify paths\n",
    "import os\n",
    "\n",
    "# EQM checkpoint (UPDATE THIS PATH IF NEEDED)\n",
    "EQM_CHECKPOINT = \"/content/drive/MyDrive/EQM_Checkpoints5/checkpoint_90.pth\"\n",
    "\n",
    "# Config and data paths\n",
    "EQM_CONFIG = \"/content/EQM-Training/configs/darcy_flow_eqm.yaml\"\n",
    "DATA_PATH = \"/content/EQM-Training/data/2D_DarcyFlow_beta1.0_Train.hdf5\"\n",
    "\n",
    "# Check if files exist\n",
    "print(\"Checking paths...\")\n",
    "print(f\"EQM Checkpoint: {'✓' if os.path.exists(EQM_CHECKPOINT) else '✗ NOT FOUND'} {EQM_CHECKPOINT}\")\n",
    "print(f\"EQM Config: {'✓' if os.path.exists(EQM_CONFIG) else '✗ NOT FOUND'} {EQM_CONFIG}\")\n",
    "print(f\"Data: {'✓' if os.path.exists(DATA_PATH) else '✗ NOT FOUND'} {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training Configuration\n",
    "\n",
    "Adjust these parameters as needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "CONFIG = {\n",
    "    # Data\n",
    "    \"train_samples\": 800,\n",
    "    \"val_samples\": 200,\n",
    "    \"batch_size\": 4,\n",
    "    \n",
    "    # Training\n",
    "    \"epochs\": 100,\n",
    "    \"lr\": 1e-3,\n",
    "    \n",
    "    # Loss weights\n",
    "    \"mse_weight\": 0.8,\n",
    "    \"energy_weight\": 0.2,\n",
    "    \"energy_loss_mode\": \"relative\",  # Options: 'relative', 'threshold', 'normalized'\n",
    "    \"energy_temperature\": 1.0,\n",
    "    \n",
    "    # Saving\n",
    "    \"checkpoint_save_path\": \"/content/drive/MyDrive/fno_with_energy.pth\",\n",
    "    \"output_plot\": \"/content/drive/MyDrive/fno_training_curves.png\",\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/EQM-Training\n",
    "\n",
    "!python train_fno_with_energy.py \\\n",
    "    --data_path {DATA_PATH} \\\n",
    "    --eqm_checkpoint {EQM_CHECKPOINT} \\\n",
    "    --eqm_config {EQM_CONFIG} \\\n",
    "    --train_samples {CONFIG[\"train_samples\"]} \\\n",
    "    --val_samples {CONFIG[\"val_samples\"]} \\\n",
    "    --batch_size {CONFIG[\"batch_size\"]} \\\n",
    "    --epochs {CONFIG[\"epochs\"]} \\\n",
    "    --lr {CONFIG[\"lr\"]} \\\n",
    "    --mse_weight {CONFIG[\"mse_weight\"]} \\\n",
    "    --energy_weight {CONFIG[\"energy_weight\"]} \\\n",
    "    --energy_loss_mode {CONFIG[\"energy_loss_mode\"]} \\\n",
    "    --energy_temperature {CONFIG[\"energy_temperature\"]} \\\n",
    "    --checkpoint_save_path {CONFIG[\"checkpoint_save_path\"]} \\\n",
    "    --output_plot {CONFIG[\"output_plot\"]} \\\n",
    "    --save_every 25 \\\n",
    "    --device cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. View Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "if os.path.exists(CONFIG[\"output_plot\"]):\n",
    "    display(Image(filename=CONFIG[\"output_plot\"]))\n",
    "else:\n",
    "    print(\"Training curves not found. Training may still be in progress.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import sys\n",
    "sys.path.insert(0, '/content/EQM-Training')\n",
    "sys.path.insert(0, '/content/EQM-Training/Neural-Solver-Library-main')\n",
    "\n",
    "from models.FNO import Model as FNO\n",
    "from energy_regularization import EnergyRegularizationLoss\n",
    "\n",
    "# Load trained FNO model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "checkpoint = torch.load(CONFIG[\"checkpoint_save_path\"].replace('.pth', '_best.pth'), map_location=device)\n",
    "print(f\"Loaded checkpoint from epoch {checkpoint['epoch']}\")\n",
    "print(f\"Validation loss: {checkpoint['val_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data and visualize predictions\n",
    "with h5py.File(DATA_PATH, 'r') as f:\n",
    "    test_data = np.array(f['tensor'][900:905]).astype(np.float32)  # 5 test samples\n",
    "\n",
    "# Normalize\n",
    "norm_stats = checkpoint['normalization_stats']\n",
    "test_normalized = 2 * (test_data - norm_stats['output_min']) / (norm_stats['output_max'] - norm_stats['output_min']) - 1\n",
    "\n",
    "print(f\"Test samples shape: {test_data.shape}\")\n",
    "print(f\"Normalized range: [{test_normalized.min():.2f}, {test_normalized.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample predictions\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "\n",
    "for i in range(5):\n",
    "    # Ground truth\n",
    "    axes[0, i].imshow(test_data[i], cmap='viridis')\n",
    "    axes[0, i].set_title(f'Ground Truth {i+1}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Show normalized version\n",
    "    axes[1, i].imshow(test_normalized[i], cmap='viridis')\n",
    "    axes[1, i].set_title(f'Normalized {i+1}')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.suptitle('Test Samples', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Energy: FNO vs Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize energy model\n",
    "energy_loss = EnergyRegularizationLoss(\n",
    "    checkpoint_path=EQM_CHECKPOINT,\n",
    "    config_path=EQM_CONFIG,\n",
    "    device=device,\n",
    "    training_data_path=DATA_PATH,\n",
    "    num_calibration_samples=100,\n",
    "    loss_mode='relative'\n",
    ")\n",
    "\n",
    "# Compute energy for test samples\n",
    "test_tensor = torch.from_numpy(test_normalized[:, np.newaxis, :, :]).float().to(device)\n",
    "energy_stats = energy_loss.get_energy_stats(test_tensor)\n",
    "\n",
    "print(f\"\\nTest Sample Energy Statistics:\")\n",
    "print(f\"  Mean: {energy_stats['mean']:.2f}\")\n",
    "print(f\"  Std:  {energy_stats['std']:.2f}\")\n",
    "print(f\"  Min:  {energy_stats['min']:.2f}\")\n",
    "print(f\"  Max:  {energy_stats['max']:.2f}\")\n",
    "print(f\"\\nTraining Energy Statistics (reference):\")\n",
    "print(f\"  Mean: {energy_loss.energy_mean:.2f}\")\n",
    "print(f\"  Std:  {energy_loss.energy_std:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Notes\n",
    "\n",
    "**Energy Loss Modes:**\n",
    "- `relative`: Penalizes deviation from training mean (recommended)\n",
    "- `threshold`: Only penalizes outliers beyond 2σ\n",
    "- `normalized`: Scales energy to [0, 1] range\n",
    "\n",
    "**Tuning Tips:**\n",
    "- If MSE isn't improving: Decrease `energy_weight` to 0.1\n",
    "- If predictions look unphysical: Increase `energy_weight` to 0.3\n",
    "- Lower `temperature` = sharper penalty for OOD predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 7. Compare Models: MSE+Energy vs MSE-Only\n\nRun both trainings first, then compare the results:\n1. **MSE+Energy Model**: Trained with `energy_weight=0.2`\n2. **MSE-Only Model**: Trained with `energy_weight=0.0`",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Configuration for comparison\n# UPDATE THESE PATHS to your trained model checkpoints\n\nMSE_ENERGY_CHECKPOINT = \"/content/drive/MyDrive/fno_with_energy_best.pth\"  # MSE+Energy model\nMSE_ONLY_CHECKPOINT = \"/content/drive/MyDrive/fno_mse_only_best.pth\"       # MSE-only model\n\n# Verify both checkpoints exist\nprint(\"Checking model checkpoints...\")\nprint(f\"MSE+Energy: {'✓' if os.path.exists(MSE_ENERGY_CHECKPOINT) else '✗ NOT FOUND'}\")\nprint(f\"MSE-Only:   {'✓' if os.path.exists(MSE_ONLY_CHECKPOINT) else '✗ NOT FOUND'}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Load both models\nfrom models.FNO import Model as FNO\n\ndef load_fno_model(checkpoint_path, device):\n    \"\"\"Load a trained FNO model from checkpoint.\"\"\"\n    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n    \n    model = FNO(\n        img_size=(128, 128),\n        patch_size=1,\n        in_channels=1,\n        out_channels=1,\n        embed_dim=256,\n        depth=12,\n        modes=32,\n        num_blocks=8\n    ).to(device)\n    \n    model.load_state_dict(checkpoint['model_state_dict'])\n    model.eval()\n    return model, checkpoint\n\n# Load models\nprint(\"Loading MSE+Energy model...\")\nmodel_energy, ckpt_energy = load_fno_model(MSE_ENERGY_CHECKPOINT, device)\nprint(f\"  Best epoch: {ckpt_energy['epoch']}, Val loss: {ckpt_energy['val_loss']:.4f}\")\n\nprint(\"\\nLoading MSE-only model...\")\nmodel_mse, ckpt_mse = load_fno_model(MSE_ONLY_CHECKPOINT, device)\nprint(f\"  Best epoch: {ckpt_mse['epoch']}, Val loss: {ckpt_mse['val_loss']:.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Load test data (samples 1000+ are held out)\nNUM_TEST_SAMPLES = 100\n\nwith h5py.File(DATA_PATH, 'r') as f:\n    total_samples = f['tensor'].shape[0]\n    start_idx = min(1000, total_samples - NUM_TEST_SAMPLES)\n    \n    # Load outputs (u) and inputs (a)\n    test_outputs = np.array(f['tensor'][start_idx:start_idx + NUM_TEST_SAMPLES]).astype(np.float32)\n    test_inputs = np.array(f['x-coordinate'][start_idx:start_idx + NUM_TEST_SAMPLES]).astype(np.float32)\n\nprint(f\"Loaded {NUM_TEST_SAMPLES} test samples (indices {start_idx} to {start_idx + NUM_TEST_SAMPLES})\")\n\n# Normalize using saved stats\nnorm_stats = ckpt_energy['normalization_stats']\n\ninputs_norm = 2 * (test_inputs - norm_stats['input_min']) / (norm_stats['input_max'] - norm_stats['input_min']) - 1\noutputs_norm = 2 * (test_outputs - norm_stats['output_min']) / (norm_stats['output_max'] - norm_stats['output_min']) - 1\n\n# Convert to tensors\ninputs_tensor = torch.from_numpy(inputs_norm[:, np.newaxis, :, :]).float().to(device)\ntargets_tensor = torch.from_numpy(outputs_norm[:, np.newaxis, :, :]).float().to(device)\n\nprint(f\"Input shape: {inputs_tensor.shape}\")\nprint(f\"Target shape: {targets_tensor.shape}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Initialize energy computation\nenergy_loss = EnergyRegularizationLoss(\n    checkpoint_path=EQM_CHECKPOINT,\n    config_path=EQM_CONFIG,\n    device=device,\n    training_data_path=DATA_PATH,\n    num_calibration_samples=100,\n    loss_mode='relative'\n)\n\ntraining_energy_mean = energy_loss.energy_mean\ntraining_energy_std = energy_loss.energy_std\n\nprint(f\"Training data energy reference:\")\nprint(f\"  Mean: {training_energy_mean:.2f}\")\nprint(f\"  Std:  {training_energy_std:.2f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Evaluate both models\nprint(\"Evaluating models on test set...\")\n\nwith torch.no_grad():\n    # MSE+Energy model predictions\n    preds_energy = model_energy(inputs_tensor)\n    mse_energy = ((preds_energy - targets_tensor) ** 2).mean(dim=(1, 2, 3))\n    energies_energy = energy_loss.compute_energy(preds_energy)\n    \n    # MSE-only model predictions  \n    preds_mse = model_mse(inputs_tensor)\n    mse_mse = ((preds_mse - targets_tensor) ** 2).mean(dim=(1, 2, 3))\n    energies_mse = energy_loss.compute_energy(preds_mse)\n    \n    # Ground truth energy\n    gt_energies = energy_loss.compute_energy(targets_tensor)\n\n# Convert to numpy\nmse_energy_np = mse_energy.cpu().numpy()\nmse_mse_np = mse_mse.cpu().numpy()\nenergies_energy_np = energies_energy.cpu().numpy()\nenergies_mse_np = energies_mse.cpu().numpy()\ngt_energies_np = gt_energies.cpu().numpy()\n\n# Print comparison table\nprint(\"\\n\" + \"=\"*60)\nprint(\"COMPARISON RESULTS\")\nprint(\"=\"*60)\nprint(f\"\\n{'Metric':<25} {'MSE+Energy':>15} {'MSE-Only':>15}\")\nprint(\"-\" * 55)\nprint(f\"{'MSE (mean)':<25} {mse_energy_np.mean():>15.6f} {mse_mse_np.mean():>15.6f}\")\nprint(f\"{'MSE (std)':<25} {mse_energy_np.std():>15.6f} {mse_mse_np.std():>15.6f}\")\nprint(f\"{'Energy (mean)':<25} {energies_energy_np.mean():>15.2f} {energies_mse_np.mean():>15.2f}\")\nprint(f\"{'Energy (std)':<25} {energies_energy_np.std():>15.2f} {energies_mse_np.std():>15.2f}\")\n\n# Energy deviation from training mean\ndev_energy = abs(energies_energy_np.mean() - training_energy_mean)\ndev_mse = abs(energies_mse_np.mean() - training_energy_mean)\n\nprint(f\"\\n{'Energy dev from train μ':<25} {dev_energy:>15.2f} {dev_mse:>15.2f}\")\nprint(f\"{'Deviation (in σ units)':<25} {dev_energy/training_energy_std:>15.2f} {dev_mse/training_energy_std:>15.2f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Visualization: Energy Distribution Comparison\nfig, axes = plt.subplots(1, 3, figsize=(18, 5))\n\n# 1. Energy Distribution\nax1 = axes[0]\nbins = np.linspace(\n    min(gt_energies_np.min(), energies_energy_np.min(), energies_mse_np.min()),\n    max(gt_energies_np.max(), energies_energy_np.max(), energies_mse_np.max()),\n    40\n)\n\nax1.hist(gt_energies_np, bins=bins, alpha=0.5, label=f'Ground Truth (μ={gt_energies_np.mean():.0f})', \n         color='green', density=True)\nax1.hist(energies_energy_np, bins=bins, alpha=0.5, \n         label=f'MSE+Energy (μ={energies_energy_np.mean():.0f})', color='blue', density=True)\nax1.hist(energies_mse_np, bins=bins, alpha=0.5, \n         label=f'MSE-Only (μ={energies_mse_np.mean():.0f})', color='red', density=True)\n\nax1.axvline(training_energy_mean, color='black', linestyle='--', linewidth=2, \n            label=f'Training μ={training_energy_mean:.0f}')\nax1.axvspan(training_energy_mean - 2*training_energy_std, \n            training_energy_mean + 2*training_energy_std, \n            alpha=0.1, color='gray', label='Training ±2σ')\n\nax1.set_xlabel('Energy', fontsize=12)\nax1.set_ylabel('Density', fontsize=12)\nax1.set_title('Energy Distribution', fontsize=14, fontweight='bold')\nax1.legend(fontsize=9)\n\n# 2. MSE Distribution\nax2 = axes[1]\nmse_bins = np.linspace(0, max(mse_energy_np.max(), mse_mse_np.max()), 30)\n\nax2.hist(mse_energy_np, bins=mse_bins, alpha=0.6, \n         label=f'MSE+Energy (μ={mse_energy_np.mean():.4f})', color='blue')\nax2.hist(mse_mse_np, bins=mse_bins, alpha=0.6, \n         label=f'MSE-Only (μ={mse_mse_np.mean():.4f})', color='red')\n\nax2.set_xlabel('MSE per Sample', fontsize=12)\nax2.set_ylabel('Count', fontsize=12)\nax2.set_title('MSE Distribution', fontsize=14, fontweight='bold')\nax2.legend(fontsize=10)\n\n# 3. MSE vs Energy Scatter\nax3 = axes[2]\nax3.scatter(mse_energy_np, energies_energy_np, alpha=0.6, label='MSE+Energy', color='blue', s=30)\nax3.scatter(mse_mse_np, energies_mse_np, alpha=0.6, label='MSE-Only', color='red', s=30)\n\nax3.axhline(training_energy_mean, color='black', linestyle='--', alpha=0.7, label='Training Energy Mean')\nax3.axhspan(training_energy_mean - 2*training_energy_std, \n            training_energy_mean + 2*training_energy_std, alpha=0.1, color='gray')\n\nax3.set_xlabel('MSE', fontsize=12)\nax3.set_ylabel('Energy', fontsize=12)\nax3.set_title('MSE vs Energy Trade-off', fontsize=14, fontweight='bold')\nax3.legend(fontsize=10)\n\nplt.suptitle('Model Comparison: MSE+Energy vs MSE-Only', fontsize=16, fontweight='bold')\nplt.tight_layout()\nplt.savefig('/content/drive/MyDrive/model_comparison_distributions.png', dpi=150, bbox_inches='tight')\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Visualization: Sample Predictions Comparison\npreds_energy_np = preds_energy.cpu().numpy()\npreds_mse_np = preds_mse.cpu().numpy()\n\nfig, axes = plt.subplots(4, 5, figsize=(20, 16))\n\nsample_indices = [0, 1, 2, 3, 4]  # Show 5 samples\n\nfor col, idx in enumerate(sample_indices):\n    # Row 0: Input a(x)\n    axes[0, col].imshow(inputs_norm[idx], cmap='viridis')\n    axes[0, col].set_title(f'Input a(x) #{idx+1}', fontsize=11)\n    axes[0, col].axis('off')\n    \n    # Row 1: Ground Truth u(x)\n    axes[1, col].imshow(outputs_norm[idx], cmap='viridis')\n    axes[1, col].set_title(f'Ground Truth', fontsize=11)\n    axes[1, col].axis('off')\n    \n    # Row 2: MSE+Energy prediction\n    axes[2, col].imshow(preds_energy_np[idx, 0], cmap='viridis')\n    mse_e = mse_energy_np[idx]\n    energy_e = energies_energy_np[idx]\n    axes[2, col].set_title(f'MSE+Energy\\nMSE={mse_e:.4f}, E={energy_e:.0f}', fontsize=10)\n    axes[2, col].axis('off')\n    \n    # Row 3: MSE-Only prediction\n    axes[3, col].imshow(preds_mse_np[idx, 0], cmap='viridis')\n    mse_m = mse_mse_np[idx]\n    energy_m = energies_mse_np[idx]\n    axes[3, col].set_title(f'MSE-Only\\nMSE={mse_m:.4f}, E={energy_m:.0f}', fontsize=10)\n    axes[3, col].axis('off')\n\n# Row labels\nfig.text(0.02, 0.88, 'Input', fontsize=12, fontweight='bold', rotation=90, va='center')\nfig.text(0.02, 0.65, 'Ground\\nTruth', fontsize=12, fontweight='bold', rotation=90, va='center')\nfig.text(0.02, 0.42, 'MSE+\\nEnergy', fontsize=12, fontweight='bold', rotation=90, va='center')\nfig.text(0.02, 0.18, 'MSE\\nOnly', fontsize=12, fontweight='bold', rotation=90, va='center')\n\nplt.suptitle('Sample Predictions Comparison', fontsize=16, fontweight='bold')\nplt.tight_layout(rect=[0.04, 0, 1, 0.96])\nplt.savefig('/content/drive/MyDrive/model_comparison_samples.png', dpi=150, bbox_inches='tight')\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Print final analysis and interpretation\nprint(\"=\"*70)\nprint(\"FINAL ANALYSIS\")\nprint(\"=\"*70)\n\nmse_winner = \"MSE-Only\" if mse_mse_np.mean() < mse_energy_np.mean() else \"MSE+Energy\"\nenergy_winner = \"MSE+Energy\" if dev_energy < dev_mse else \"MSE-Only\"\n\nprint(f\"\\n✓ MSE Winner: {mse_winner}\")\nprint(f\"  MSE+Energy: {mse_energy_np.mean():.6f}\")\nprint(f\"  MSE-Only:   {mse_mse_np.mean():.6f}\")\n\nprint(f\"\\n✓ Energy (Physical Plausibility) Winner: {energy_winner}\")\nprint(f\"  MSE+Energy deviation: {dev_energy:.2f} ({dev_energy/training_energy_std:.2f}σ from training mean)\")\nprint(f\"  MSE-Only deviation:   {dev_mse:.2f} ({dev_mse/training_energy_std:.2f}σ from training mean)\")\n\nprint(\"\\n\" + \"-\"*70)\nprint(\"INTERPRETATION\")\nprint(\"-\"*70)\n\nif mse_winner == \"MSE-Only\" and energy_winner == \"MSE+Energy\":\n    print(\"\"\"\n✓ TRADE-OFF DETECTED (Expected Behavior)\n\nThe results show the classic accuracy vs. physical plausibility trade-off:\n\n• MSE-Only achieves LOWER reconstruction error\n  → It's better at matching exact pixel values\n  \n• BUT MSE-Only predictions are OUT-OF-DISTRIBUTION\n  → Energy is significantly different from training data\n  → Predictions may not respect physical constraints\n  \n• MSE+Energy has HIGHER reconstruction error\n  → But predictions stay IN-DISTRIBUTION\n  → Energy close to training mean = physically plausible\n  \nCONCLUSION: Energy regularization successfully constrains the FNO\nto produce physically meaningful predictions, at the cost of some\nreconstruction accuracy. This is the intended behavior!\n\"\"\")\nelif mse_winner == \"MSE+Energy\" and energy_winner == \"MSE+Energy\":\n    print(\"\"\"\n✓ MSE+ENERGY WINS BOTH!\n\nSurprising result: Energy regularization helped the model learn\nbetter representations that also improve reconstruction accuracy.\n\nThis could mean:\n• The energy function captures useful physical structure\n• Regularization prevented overfitting\n• The physics-informed constraint guided optimization to better minima\n\"\"\")\nelse:\n    print(\"\"\"\nResults show MSE-Only may be preferable for this dataset.\nConsider reducing energy_weight or investigating the energy function calibration.\n\"\"\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FNO Training with Energy Regularization\n",
    "\n",
    "Train a Fourier Neural Operator (FNO) on Darcy Flow with energy-based regularization.\n",
    "\n",
    "**Loss Function**: `0.8 × MSE + 0.2 × Energy`\n",
    "\n",
    "The energy regularization uses your trained EQM model to keep predictions physically plausible and in-distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repositories\n",
    "!git clone https://github.com/MehdiMHeydari/EQM-Training.git\n",
    "!git clone https://github.com/thuml/Neural-Solver-Library.git\n",
    "\n",
    "# Move Neural-Solver-Library to expected location\n",
    "!mv Neural-Solver-Library /content/EQM-Training/Neural-Solver-Library-main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch torchvision einops omegaconf h5py matplotlib scipy tqdm timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify paths\n",
    "import os\n",
    "\n",
    "# EQM checkpoint (UPDATE THIS PATH IF NEEDED)\n",
    "EQM_CHECKPOINT = \"/content/drive/MyDrive/EQM_Checkpoints5/checkpoint_90.pth\"\n",
    "\n",
    "# Config and data paths\n",
    "EQM_CONFIG = \"/content/EQM-Training/configs/darcy_flow_eqm.yaml\"\n",
    "DATA_PATH = \"/content/EQM-Training/data/2D_DarcyFlow_beta1.0_Train.hdf5\"\n",
    "\n",
    "# Check if files exist\n",
    "print(\"Checking paths...\")\n",
    "print(f\"EQM Checkpoint: {'✓' if os.path.exists(EQM_CHECKPOINT) else '✗ NOT FOUND'} {EQM_CHECKPOINT}\")\n",
    "print(f\"EQM Config: {'✓' if os.path.exists(EQM_CONFIG) else '✗ NOT FOUND'} {EQM_CONFIG}\")\n",
    "print(f\"Data: {'✓' if os.path.exists(DATA_PATH) else '✗ NOT FOUND'} {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training Configuration\n",
    "\n",
    "Adjust these parameters as needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "CONFIG = {\n",
    "    # Data\n",
    "    \"train_samples\": 800,\n",
    "    \"val_samples\": 200,\n",
    "    \"batch_size\": 4,\n",
    "    \n",
    "    # Training\n",
    "    \"epochs\": 100,\n",
    "    \"lr\": 1e-3,\n",
    "    \n",
    "    # Loss weights\n",
    "    \"mse_weight\": 0.8,\n",
    "    \"energy_weight\": 0.2,\n",
    "    \"energy_loss_mode\": \"relative\",  # Options: 'relative', 'threshold', 'normalized'\n",
    "    \"energy_temperature\": 1.0,\n",
    "    \n",
    "    # Saving\n",
    "    \"checkpoint_save_path\": \"/content/drive/MyDrive/fno_with_energy.pth\",\n",
    "    \"output_plot\": \"/content/drive/MyDrive/fno_training_curves.png\",\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/EQM-Training\n",
    "\n",
    "!python train_fno_with_energy.py \\\n",
    "    --data_path {DATA_PATH} \\\n",
    "    --eqm_checkpoint {EQM_CHECKPOINT} \\\n",
    "    --eqm_config {EQM_CONFIG} \\\n",
    "    --train_samples {CONFIG[\"train_samples\"]} \\\n",
    "    --val_samples {CONFIG[\"val_samples\"]} \\\n",
    "    --batch_size {CONFIG[\"batch_size\"]} \\\n",
    "    --epochs {CONFIG[\"epochs\"]} \\\n",
    "    --lr {CONFIG[\"lr\"]} \\\n",
    "    --mse_weight {CONFIG[\"mse_weight\"]} \\\n",
    "    --energy_weight {CONFIG[\"energy_weight\"]} \\\n",
    "    --energy_loss_mode {CONFIG[\"energy_loss_mode\"]} \\\n",
    "    --energy_temperature {CONFIG[\"energy_temperature\"]} \\\n",
    "    --checkpoint_save_path {CONFIG[\"checkpoint_save_path\"]} \\\n",
    "    --output_plot {CONFIG[\"output_plot\"]} \\\n",
    "    --save_every 25 \\\n",
    "    --device cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. View Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "if os.path.exists(CONFIG[\"output_plot\"]):\n",
    "    display(Image(filename=CONFIG[\"output_plot\"]))\n",
    "else:\n",
    "    print(\"Training curves not found. Training may still be in progress.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import sys\n",
    "sys.path.insert(0, '/content/EQM-Training')\n",
    "sys.path.insert(0, '/content/EQM-Training/Neural-Solver-Library-main')\n",
    "\n",
    "from models.FNO import Model as FNO\n",
    "from energy_regularization import EnergyRegularizationLoss\n",
    "\n",
    "# Load trained FNO model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "checkpoint = torch.load(CONFIG[\"checkpoint_save_path\"].replace('.pth', '_best.pth'), map_location=device)\n",
    "print(f\"Loaded checkpoint from epoch {checkpoint['epoch']}\")\n",
    "print(f\"Validation loss: {checkpoint['val_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data and visualize predictions\n",
    "with h5py.File(DATA_PATH, 'r') as f:\n",
    "    test_data = np.array(f['tensor'][900:905]).astype(np.float32)  # 5 test samples\n",
    "\n",
    "# Normalize\n",
    "norm_stats = checkpoint['normalization_stats']\n",
    "test_normalized = 2 * (test_data - norm_stats['output_min']) / (norm_stats['output_max'] - norm_stats['output_min']) - 1\n",
    "\n",
    "print(f\"Test samples shape: {test_data.shape}\")\n",
    "print(f\"Normalized range: [{test_normalized.min():.2f}, {test_normalized.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample predictions\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "\n",
    "for i in range(5):\n",
    "    # Ground truth\n",
    "    axes[0, i].imshow(test_data[i], cmap='viridis')\n",
    "    axes[0, i].set_title(f'Ground Truth {i+1}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Show normalized version\n",
    "    axes[1, i].imshow(test_normalized[i], cmap='viridis')\n",
    "    axes[1, i].set_title(f'Normalized {i+1}')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.suptitle('Test Samples', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Energy: FNO vs Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize energy model\n",
    "energy_loss = EnergyRegularizationLoss(\n",
    "    checkpoint_path=EQM_CHECKPOINT,\n",
    "    config_path=EQM_CONFIG,\n",
    "    device=device,\n",
    "    training_data_path=DATA_PATH,\n",
    "    num_calibration_samples=100,\n",
    "    loss_mode='relative'\n",
    ")\n",
    "\n",
    "# Compute energy for test samples\n",
    "test_tensor = torch.from_numpy(test_normalized[:, np.newaxis, :, :]).float().to(device)\n",
    "energy_stats = energy_loss.get_energy_stats(test_tensor)\n",
    "\n",
    "print(f\"\\nTest Sample Energy Statistics:\")\n",
    "print(f\"  Mean: {energy_stats['mean']:.2f}\")\n",
    "print(f\"  Std:  {energy_stats['std']:.2f}\")\n",
    "print(f\"  Min:  {energy_stats['min']:.2f}\")\n",
    "print(f\"  Max:  {energy_stats['max']:.2f}\")\n",
    "print(f\"\\nTraining Energy Statistics (reference):\")\n",
    "print(f\"  Mean: {energy_loss.energy_mean:.2f}\")\n",
    "print(f\"  Std:  {energy_loss.energy_std:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Notes\n",
    "\n",
    "**Energy Loss Modes:**\n",
    "- `relative`: Penalizes deviation from training mean (recommended)\n",
    "- `threshold`: Only penalizes outliers beyond 2σ\n",
    "- `normalized`: Scales energy to [0, 1] range\n",
    "\n",
    "**Tuning Tips:**\n",
    "- If MSE isn't improving: Decrease `energy_weight` to 0.1\n",
    "- If predictions look unphysical: Increase `energy_weight` to 0.3\n",
    "- Lower `temperature` = sharper penalty for OOD predictions"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# EQM Training for Darcy Flow Neural Operator\n\nThis notebook trains an Equilibrium Matching model to learn the mapping from permeability fields a(x,y) to solution fields u(x,y) for Darcy flow PDEs.\n\n**What this does:** Learns a conditional flow from input a(x,y) ‚Üí output u(x,y) using paired data.\n\n## Before Running:\n1. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí GPU\n2. **Upload HDF5**: Upload `2D_DarcyFlow_beta1.0_Train.hdf5` to Google Drive\n3. **Update path**: Change `DRIVE_DATA_PATH` in Cell 3\n\n## Recommended Workflow:\n1. Run Cells 1-5 (setup and verification)\n2. **Run Cell 6 (TensorBoard) - Keep this cell running!**\n3. Run Cell 7 (start training) in a separate view\n4. Monitor progress in TensorBoard while training runs\n5. Save results (Cells 8-9) after training completes"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup - Clone Repository and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/MehdiMHeydari/EQM-Training.git\n",
    "%cd EQM-Training\n",
    "\n",
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Installing dependencies... (this may take 3-5 minutes)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch torchvision\n",
    "!pip install -q h5py einops omegaconf tensorboard POT\n",
    "!pip install -q -e .\n",
    "\n",
    "print(\"\\n‚úÖ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Copy Data from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# ‚ö†Ô∏è CHANGE THIS PATH to match your Google Drive location!\n",
    "DRIVE_DATA_PATH = \"/content/drive/MyDrive/2D_DarcyFlow_beta1.0_Train.hdf5\"\n",
    "\n",
    "# Local path (don't change)\n",
    "LOCAL_DATA_PATH = \"data/2D_DarcyFlow_beta1.0_Train.hdf5\"\n",
    "\n",
    "print(\"Copying data from Google Drive...\")\n",
    "print(f\"Source: {DRIVE_DATA_PATH}\")\n",
    "print(f\"Destination: {LOCAL_DATA_PATH}\")\n",
    "\n",
    "if os.path.exists(DRIVE_DATA_PATH):\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    shutil.copy(DRIVE_DATA_PATH, LOCAL_DATA_PATH)\n",
    "    \n",
    "    # Verify\n",
    "    size_mb = os.path.getsize(LOCAL_DATA_PATH) / (1024**2)\n",
    "    print(f\"\\n‚úÖ Data copied successfully!\")\n",
    "    print(f\"   File size: {size_mb:.2f} MB\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå ERROR: File not found at {DRIVE_DATA_PATH}\")\n",
    "    print(\"Please update DRIVE_DATA_PATH in this cell!\")\n",
    "    raise FileNotFoundError(f\"Data file not found: {DRIVE_DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Verify Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test imports\nprint(\"Testing imports...\")\nfrom physics_flow_matching.utils.dataset import DarcyFlow\nfrom physics_flow_matching.unet.unet_bb import UNetModelWrapper\nfrom torchcfm.conditional_flow_matching import EquilibriumMatching\nimport torch\n\nprint(\"‚úÖ All imports successful!\")\n\n# Test GPU\nif torch.cuda.is_available():\n    print(f\"‚úÖ GPU available: {torch.cuda.get_device_name(0)}\")\n    print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\nelse:\n    print(\"‚ö†Ô∏è  WARNING: No GPU detected!\")\n    print(\"   Go to: Runtime ‚Üí Change runtime type ‚Üí GPU\")\n\n# Test dataset loading with conditional format\nprint(\"\\nTesting dataset...\")\ndataset = DarcyFlow(\n    hdf5_path=\"data/2D_DarcyFlow_beta1.0_Train.hdf5\",\n    normalize=True,\n    use_eqm_format=False  # Conditional: x0=a(x,y), x1=u(x,y)\n)\n\nprint(f\"‚úÖ Dataset loaded: {len(dataset)} samples\")\nprint(f\"   Sample shape: {dataset.shape}\")\n\n# Test sample\nx0, x1 = dataset[0]\nprint(f\"   x0 (input a) shape: {x0.shape}\")\nprint(f\"   x1 (output u) shape: {x1.shape}\")\nprint(f\"   x0 stats: min={x0.min():.3f}, max={x0.max():.3f}, mean={x0.mean():.3f}\")\nprint(f\"   x1 stats: min={x1.min():.3f}, max={x1.max():.3f}, mean={x1.mean():.3f}\")\n\nprint(\"\\nüéâ Everything is ready for training!\")\nprint(\"Model will learn: a(x,y) ‚Üí u(x,y)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: View/Modify Configuration (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View current config\n",
    "!cat configs/darcy_flow_eqm.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Modify config for Colab\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "config = OmegaConf.load(\"configs/darcy_flow_eqm.yaml\")\n",
    "\n",
    "# Adjust for Colab\n",
    "config.device = \"cuda\"  # Use GPU\n",
    "config.dataloader.batch_size = 32  # Adjust if needed\n",
    "config.num_epochs = 100  # Change as desired\n",
    "config.save_epoch_int = 10  # Save every 10 epochs\n",
    "\n",
    "# Save modified config\n",
    "OmegaConf.save(config, \"configs/darcy_flow_eqm.yaml\")\n",
    "print(\"‚úÖ Config updated!\")\n",
    "print(f\"   Device: {config.device}\")\n",
    "print(f\"   Batch size: {config.dataloader.batch_size}\")\n",
    "print(f\"   Epochs: {config.num_epochs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Launch TensorBoard (BEFORE Training)\n",
    "\n",
    "**‚ö†Ô∏è IMPORTANT**: Run this cell FIRST, then run the training cell below.\n",
    "\n",
    "This cell will keep running and display training metrics in real-time.\n",
    "You can scroll down and start training while TensorBoard runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch TensorBoard (run this BEFORE training)\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir experiments/darcy_flow_eqm\n",
    "\n",
    "print(\"\\nüìä TensorBoard is running!\")\n",
    "print(\"Scroll down and run the next cell to start training.\")\n",
    "print(\"Training metrics will appear here in real-time.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Start Training! üöÄ\n",
    "\n",
    "**Run this cell AFTER starting TensorBoard above.**\n",
    "\n",
    "Training will run here, while TensorBoard displays metrics above.\n",
    "\n",
    "**Tip**: You can scroll between this cell and TensorBoard to monitor progress!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(\"üöÄ Starting training...\")\n",
    "print(\"Monitor progress in TensorBoard above!\\n\")\n",
    "\n",
    "!python physics_flow_matching/train_scripts/train_unet_eqm.py configs/darcy_flow_eqm.yaml\n",
    "\n",
    "print(\"\\n‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Save Results to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "experiment_path = \"experiments/darcy_flow_eqm\"\n",
    "drive_save_path = \"/content/drive/MyDrive/EQM_Experiments\"\n",
    "\n",
    "if os.path.exists(experiment_path):\n",
    "    print(f\"Copying experiment to Google Drive...\")\n",
    "    print(f\"Destination: {drive_save_path}\")\n",
    "    \n",
    "    # Copy entire experiment folder\n",
    "    shutil.copytree(experiment_path, drive_save_path, dirs_exist_ok=True)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Experiment saved to Google Drive!\")\n",
    "    print(f\"   Location: {drive_save_path}\")\n",
    "    \n",
    "    # List saved checkpoints\n",
    "    checkpoint_dir = os.path.join(drive_save_path, \"exp_1/saved_state\")\n",
    "    if os.path.exists(checkpoint_dir):\n",
    "        checkpoints = [f for f in os.listdir(checkpoint_dir) if f.endswith('.pth')]\n",
    "        print(f\"\\n   Saved checkpoints ({len(checkpoints)}):\")\n",
    "        for ckpt in sorted(checkpoints):\n",
    "            print(f\"      - {ckpt}\")\n",
    "else:\n",
    "    print(\"‚ùå No experiment folder found!\")\n",
    "    print(\"   Make sure training has started.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Download Checkpoints (Alternative to Drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip and download checkpoints\n",
    "from google.colab import files\n",
    "\n",
    "!zip -r checkpoints.zip experiments/darcy_flow_eqm/exp_1/saved_state/\n",
    "files.download('checkpoints.zip')\n",
    "\n",
    "print(\"‚úÖ Checkpoints zipped and downloading...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Workflow Summary\n",
    "\n",
    "### Correct Order:\n",
    "1. ‚úÖ Cells 1-4: Setup and configuration\n",
    "2. ‚úÖ **Cell 5: Launch TensorBoard** (keep running)\n",
    "3. ‚úÖ **Cell 6: Start training** (runs while TensorBoard displays metrics)\n",
    "4. ‚úÖ Cells 7-8: Save results after training completes\n",
    "\n",
    "### Tips:\n",
    "- **TensorBoard refreshes automatically** - just scroll up to check progress\n",
    "- **Training output appears in Cell 6** - you'll see epoch updates there\n",
    "- **Both cells run simultaneously** - this is the correct behavior!\n",
    "- **Checkpoints save automatically** - every 10 epochs by default\n",
    "\n",
    "---\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### Out of Memory (OOM)\n",
    "Reduce batch size in Step 4:\n",
    "```python\n",
    "config.dataloader.batch_size = 16  # or 8, or 4\n",
    "```\n",
    "\n",
    "### Training too slow\n",
    "Check GPU is enabled:\n",
    "```python\n",
    "!nvidia-smi\n",
    "```\n",
    "\n",
    "### Runtime disconnected\n",
    "Resume training:\n",
    "1. Re-run cells 1-3\n",
    "2. Modify config: `config.restart = True`, `config.restart_epoch = <last_epoch>`\n",
    "3. Re-run training\n",
    "\n",
    "### TensorBoard shows \"No dashboards active\"\n",
    "Wait a few seconds after starting training - metrics appear after first epoch.\n",
    "\n",
    "### Need help?\n",
    "Check `COLAB_SETUP.md` for detailed troubleshooting guide."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
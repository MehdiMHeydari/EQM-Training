{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# EQM Training for Darcy Flow Neural Operator\n\nThis notebook trains an Equilibrium Matching model for Darcy flow PDEs using **unconditional generation**.\n\n**What this does:** Learns to generate solution fields u(x,y) from random noise, without using input permeability fields a(x,y).\n\n## Before Running:\n1. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí GPU\n2. **Upload HDF5**: Upload `2D_DarcyFlow_beta1.0_Train.hdf5` to Google Drive\n3. **Update path**: Change `DRIVE_DATA_PATH` in Cell 3\n\n## Recommended Workflow:\n1. Run Cells 1-5 (setup and verification)\n2. **Run Cell 6 (TensorBoard) - Keep this cell running!**\n3. Run Cell 7 (start training) in a separate view\n4. Monitor progress in TensorBoard while training runs\n5. Sample from trained model (Cell 9) after training completes\n6. Save results (Cells 10-11) after training completes"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup - Clone Repository and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/MehdiMHeydari/EQM-Training.git\n",
    "%cd EQM-Training\n",
    "\n",
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Installing dependencies... (this may take 3-5 minutes)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch torchvision\n",
    "!pip install -q h5py einops omegaconf tensorboard POT\n",
    "!pip install -q -e .\n",
    "\n",
    "print(\"\\n‚úÖ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Copy Data from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# ‚ö†Ô∏è CHANGE THIS PATH to match your Google Drive location!\n",
    "DRIVE_DATA_PATH = \"/content/drive/MyDrive/2D_DarcyFlow_beta1.0_Train.hdf5\"\n",
    "\n",
    "# Local path (don't change)\n",
    "LOCAL_DATA_PATH = \"data/2D_DarcyFlow_beta1.0_Train.hdf5\"\n",
    "\n",
    "print(\"Copying data from Google Drive...\")\n",
    "print(f\"Source: {DRIVE_DATA_PATH}\")\n",
    "print(f\"Destination: {LOCAL_DATA_PATH}\")\n",
    "\n",
    "if os.path.exists(DRIVE_DATA_PATH):\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    shutil.copy(DRIVE_DATA_PATH, LOCAL_DATA_PATH)\n",
    "    \n",
    "    # Verify\n",
    "    size_mb = os.path.getsize(LOCAL_DATA_PATH) / (1024**2)\n",
    "    print(f\"\\n‚úÖ Data copied successfully!\")\n",
    "    print(f\"   File size: {size_mb:.2f} MB\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå ERROR: File not found at {DRIVE_DATA_PATH}\")\n",
    "    print(\"Please update DRIVE_DATA_PATH in this cell!\")\n",
    "    raise FileNotFoundError(f\"Data file not found: {DRIVE_DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Verify Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test imports\nprint(\"Testing imports...\")\nfrom physics_flow_matching.utils.dataset import DarcyFlow\nfrom physics_flow_matching.unet.unet_bb import UNetModelWrapper\nfrom torchcfm.conditional_flow_matching import EquilibriumMatching\nimport torch\n\nprint(\"‚úÖ All imports successful!\")\n\n# Test GPU\nif torch.cuda.is_available():\n    print(f\"‚úÖ GPU available: {torch.cuda.get_device_name(0)}\")\n    print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\nelse:\n    print(\"‚ö†Ô∏è  WARNING: No GPU detected!\")\n    print(\"   Go to: Runtime ‚Üí Change runtime type ‚Üí GPU\")\n\n# Test dataset loading with UNCONDITIONAL format\nprint(\"\\nTesting dataset...\")\ndataset = DarcyFlow(\n    hdf5_path=\"data/2D_DarcyFlow_beta1.0_Train.hdf5\",\n    normalize=True,\n    use_eqm_format=True  # Unconditional: x0=empty, x1=u(x,y) only\n)\n\nprint(f\"‚úÖ Dataset loaded: {len(dataset)} samples\")\nprint(f\"   Sample shape: {dataset.shape}\")\n\n# Test sample\nx0, x1 = dataset[0]\nprint(f\"   x0 (unused) shape: {x0.shape}\")\nprint(f\"   x1 (output u) shape: {x1.shape}\")\nprint(f\"   x1 stats: min={x1.min():.3f}, max={x1.max():.3f}, mean={x1.mean():.3f}\")\n\nprint(\"\\nüéâ Everything is ready for training!\")\nprint(\"Model will learn: noise ‚Üí u(x,y) (unconditional generation)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: View/Modify Configuration (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View current config\n",
    "!cat configs/darcy_flow_eqm.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Configure training settings\nfrom omegaconf import OmegaConf\n\nconfig = OmegaConf.load(\"configs/darcy_flow_eqm.yaml\")\n\n# Training configuration\nconfig.device = \"cuda\"  # Use GPU\nconfig.dataloader.batch_size = 32  # Adjust if needed (reduce to 16 or 8 if OOM)\nconfig.num_epochs = 50  # Total epochs to train\nconfig.save_epoch_int = 5  # Save checkpoint every 5 epochs\nconfig.print_epoch_int = 1  # Print loss every epoch\n\n# Auto-backup to Google Drive\nconfig.drive_backup_path = \"/content/drive/MyDrive/EQM_Checkpoints\"  # Checkpoints saved here automatically\n\n# Save modified config\nOmegaConf.save(config, \"configs/darcy_flow_eqm.yaml\")\n\nprint(\"‚úÖ Config updated!\")\nprint(f\"   Device: {config.device}\")\nprint(f\"   Batch size: {config.dataloader.batch_size}\")\nprint(f\"   Total epochs: {config.num_epochs}\")\nprint(f\"   Save interval: Every {config.save_epoch_int} epochs\")\nprint(f\"   Auto-backup to: {config.drive_backup_path}\")\nprint(f\"\\nüìÅ Checkpoints will be automatically saved to Google Drive during training!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Launch TensorBoard (BEFORE Training)\n",
    "\n",
    "**‚ö†Ô∏è IMPORTANT**: Run this cell FIRST, then run the training cell below.\n",
    "\n",
    "This cell will keep running and display training metrics in real-time.\n",
    "You can scroll down and start training while TensorBoard runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch TensorBoard (run this BEFORE training)\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir experiments/darcy_flow_eqm\n",
    "\n",
    "print(\"\\nüìä TensorBoard is running!\")\n",
    "print(\"Scroll down and run the next cell to start training.\")\n",
    "print(\"Training metrics will appear here in real-time.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 6: Start Training! üöÄ\n\n**Run this cell AFTER starting TensorBoard above.**\n\nTraining will run for 50 epochs, automatically saving checkpoints to Google Drive every 5 epochs.\n\n**Features:**\n- ‚úÖ Checkpoints auto-saved to `/content/drive/MyDrive/EQM_Checkpoints/` every 5 epochs\n- ‚úÖ TensorBoard metrics update in real-time\n- ‚úÖ No need to run separate backup cell - it's automatic!\n\n**Progress**: Watch TensorBoard above for training metrics!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(\"üöÄ Starting training...\")\n",
    "print(\"Monitor progress in TensorBoard above!\\n\")\n",
    "\n",
    "!python physics_flow_matching/train_scripts/train_unet_eqm.py configs/darcy_flow_eqm.yaml\n",
    "\n",
    "print(\"\\n‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Step 7: Generate Samples from Trained Model (Unconditional)\n\nAfter training completes, use the trained model to generate solution fields u(x,y) from random noise.\n\n**What happens:**\n1. Starts from random Gaussian noise\n2. Follows energy gradients: dx/dœÑ = -‚àáE(x)\n3. Converges to realistic solution fields u(x,y)\n\n**Note:** Change `checkpoint_100.pth` to your actual checkpoint filename!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Generate unconditional samples from noise\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nfrom tqdm import tqdm\nfrom omegaconf import OmegaConf\n\n# Ensure we're in the right directory\nimport os\nos.chdir('/content/EQM-Training')\n\n# Import from installed package\nfrom physics_flow_matching.unet.unet_bb import UNetModelWrapper as UNetModel\n\n# Sampling parameters\nCHECKPOINT = \"/content/drive/MyDrive/EQM_Checkpoints/checkpoint_25.pth\"  # Change this!\nNUM_SAMPLES = 16\nNUM_STEPS = 100  # Gradient descent steps\nSTEP_SIZE = 0.01  # Step size for gradient descent\n\nprint(f\"Generating {NUM_SAMPLES} unconditional samples...\")\nprint(f\"Checkpoint: {CHECKPOINT}\")\nprint(f\"Gradient descent: {NUM_STEPS} steps with step_size={STEP_SIZE}\\n\")\n\n# Verify checkpoint exists\nif not os.path.exists(CHECKPOINT):\n    print(f\"‚ùå ERROR: Checkpoint not found at {CHECKPOINT}\")\n    print(\"\\nAvailable checkpoints in Google Drive:\")\n    ckpt_dir = \"/content/drive/MyDrive/EQM_Checkpoints\"\n    if os.path.exists(ckpt_dir):\n        checkpoints = [f for f in os.listdir(ckpt_dir) if f.endswith('.pth')]\n        for ckpt in sorted(checkpoints):\n            print(f\"   - {os.path.join(ckpt_dir, ckpt)}\")\n    raise FileNotFoundError(f\"Checkpoint not found: {CHECKPOINT}\")\n\n# Load config\nconfig = OmegaConf.load(\"configs/darcy_flow_eqm.yaml\")\n\n# Setup device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# Initialize model\nprint(\"Initializing model...\")\nmodel = UNetModel(\n    dim=config.unet.dim,\n    out_channels=config.unet.out_channels,\n    num_channels=config.unet.num_channels,\n    num_res_blocks=config.unet.res_blocks,\n    channel_mult=config.unet.channel_mult,\n    num_head_channels=config.unet.head_chans,\n    attention_resolutions=config.unet.attn_res,\n    dropout=config.unet.dropout,\n    use_new_attention_order=config.unet.new_attn,\n    use_scale_shift_norm=config.unet.film,\n)\n\n# Load checkpoint\nprint(f\"Loading checkpoint...\")\ncheckpoint = torch.load(CHECKPOINT, map_location=device)\nmodel.load_state_dict(checkpoint['model_state_dict'])\nmodel.to(device)\nmodel.eval()\n\n# Sample shape from config\nsample_shape = tuple(config.unet.dim)  # (C, H, W)\nprint(f\"Sample shape: {sample_shape}\")\n\n# Generate samples using gradient descent\nprint(f\"\\nGenerating {NUM_SAMPLES} samples...\")\nall_samples = []\nbatch_size = 16\nnum_batches = (NUM_SAMPLES + batch_size - 1) // batch_size\n\nfor i in tqdm(range(num_batches), desc=\"Generating samples\"):\n    current_batch_size = min(batch_size, NUM_SAMPLES - i * batch_size)\n    \n    # Start from random Gaussian noise\n    x = torch.randn(current_batch_size, *sample_shape).to(device)\n    \n    # Gradient descent loop\n    for step in range(NUM_STEPS):\n        x.requires_grad_(True)\n        \n        with torch.enable_grad():\n            # Compute energy E(x) = sum(x * model(x))\n            pred = model(x)\n            E = torch.sum(x * pred, dim=(1, 2, 3))\n            \n            # Compute gradient v = -‚àáE(x)\n            grad = -torch.autograd.grad([E.sum()], [x], create_graph=False)[0]\n        \n        # Update x (gradient descent step)\n        with torch.no_grad():\n            x = x + STEP_SIZE * grad\n    \n    # Save final samples\n    all_samples.append(x.detach().cpu().numpy())\n\nsamples = np.concatenate(all_samples, axis=0)[:NUM_SAMPLES]\n\n# Save samples\nnp.save(\"samples_unconditional.npy\", samples)\nprint(f\"\\n‚úÖ Generated {samples.shape[0]} samples!\")\nprint(f\"   Shape: {samples.shape}\")\nprint(f\"   Stats: min={samples.min():.3f}, max={samples.max():.3f}, mean={samples.mean():.3f}\")\n\n# Visualize samples\nprint(\"\\nVisualizing samples...\")\nfig, axes = plt.subplots(4, 4, figsize=(12, 12))\nfor i, ax in enumerate(axes.flat):\n    if i < len(samples):\n        im = ax.imshow(samples[i, 0], cmap='viridis')\n        ax.set_title(f'Sample {i}')\n        ax.axis('off')\n        plt.colorbar(im, ax=ax, fraction=0.046)\n\nplt.tight_layout()\nplt.savefig('unconditional_samples.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(f\"\\n‚úÖ Samples saved to: samples_unconditional.npy\")\nprint(f\"   Visualization: unconditional_samples.png\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 8: Save Results to Google Drive"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "experiment_path = \"experiments/darcy_flow_eqm\"\n",
    "drive_save_path = \"/content/drive/MyDrive/EQM_Experiments\"\n",
    "\n",
    "if os.path.exists(experiment_path):\n",
    "    print(f\"Copying experiment to Google Drive...\")\n",
    "    print(f\"Destination: {drive_save_path}\")\n",
    "    \n",
    "    # Copy entire experiment folder\n",
    "    shutil.copytree(experiment_path, drive_save_path, dirs_exist_ok=True)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Experiment saved to Google Drive!\")\n",
    "    print(f\"   Location: {drive_save_path}\")\n",
    "    \n",
    "    # List saved checkpoints\n",
    "    checkpoint_dir = os.path.join(drive_save_path, \"exp_1/saved_state\")\n",
    "    if os.path.exists(checkpoint_dir):\n",
    "        checkpoints = [f for f in os.listdir(checkpoint_dir) if f.endswith('.pth')]\n",
    "        print(f\"\\n   Saved checkpoints ({len(checkpoints)}):\")\n",
    "        for ckpt in sorted(checkpoints):\n",
    "            print(f\"      - {ckpt}\")\n",
    "else:\n",
    "    print(\"‚ùå No experiment folder found!\")\n",
    "    print(\"   Make sure training has started.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 9: Download Checkpoints (Alternative to Drive)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip and download checkpoints\n",
    "from google.colab import files\n",
    "\n",
    "!zip -r checkpoints.zip experiments/darcy_flow_eqm/exp_1/saved_state/\n",
    "files.download('checkpoints.zip')\n",
    "\n",
    "print(\"‚úÖ Checkpoints zipped and downloading...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Workflow Summary\n",
    "\n",
    "### Correct Order:\n",
    "1. ‚úÖ Cells 1-4: Setup and configuration\n",
    "2. ‚úÖ **Cell 5: Launch TensorBoard** (keep running)\n",
    "3. ‚úÖ **Cell 6: Start training** (runs while TensorBoard displays metrics)\n",
    "4. ‚úÖ Cells 7-8: Save results after training completes\n",
    "\n",
    "### Tips:\n",
    "- **TensorBoard refreshes automatically** - just scroll up to check progress\n",
    "- **Training output appears in Cell 6** - you'll see epoch updates there\n",
    "- **Both cells run simultaneously** - this is the correct behavior!\n",
    "- **Checkpoints save automatically** - every 10 epochs by default\n",
    "\n",
    "---\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### Out of Memory (OOM)\n",
    "Reduce batch size in Step 4:\n",
    "```python\n",
    "config.dataloader.batch_size = 16  # or 8, or 4\n",
    "```\n",
    "\n",
    "### Training too slow\n",
    "Check GPU is enabled:\n",
    "```python\n",
    "!nvidia-smi\n",
    "```\n",
    "\n",
    "### Runtime disconnected\n",
    "Resume training:\n",
    "1. Re-run cells 1-3\n",
    "2. Modify config: `config.restart = True`, `config.restart_epoch = <last_epoch>`\n",
    "3. Re-run training\n",
    "\n",
    "### TensorBoard shows \"No dashboards active\"\n",
    "Wait a few seconds after starting training - metrics appear after first epoch.\n",
    "\n",
    "### Need help?\n",
    "Check `COLAB_SETUP.md` for detailed troubleshooting guide."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}